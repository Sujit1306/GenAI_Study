{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e44a969",
   "metadata": {},
   "source": [
    "# Introduction to Chains and Parsers in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7de18c",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f73d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"MISTRAL_API_KEY\"]=os.getenv(\"MISTRAL_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"DEMO1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620b641",
   "metadata": {},
   "source": [
    "### Load the LLM from Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cffb20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Generative AI is a type of artificial intelligence that focuses on creating new content.\\n\\n**Key Characteristics:**\\n\\n* **Creation:** Its primary function is to generate novel outputs, such as text, images, audio, video, code, and more.\\n* **Learning from Data:** Generative AI models are trained on massive datasets of existing content, learning patterns and structures within the data.\\n* **Probabilistic Nature:** They work by predicting the probability of different elements appearing together, allowing them to create outputs that are statistically similar to the training data but not exact copies.\\n\\n**How it Works:**\\n\\nGenerative AI models typically use deep learning algorithms, particularly neural networks with architectures like:\\n\\n* **Generative Adversarial Networks (GANs):** Comprise two competing networks: a generator that creates content and a discriminator that evaluates its authenticity.\\n* **Transformer Networks:** Powerful architectures that excel at understanding and generating sequential data, such as text.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of applications, including:\\n\\n* **Text Generation:** Writing stories, articles, poems, dialogue, and code.\\n* **Image Generation:** Creating realistic images, artwork, and special effects.\\n* **Audio Generation:** Synthesizing speech, music, and sound effects.\\n* **Video Generation:** Producing short videos, animations, and special effects.\\n* **Drug Discovery:** Generating novel molecules with potential therapeutic properties.\\n* **Design and Engineering:** Assisting in the design of products, buildings, and other structures.\\n\\n**Examples:**\\n\\n* **OpenAI's GPT-3:** A text-generating model capable of producing human-quality writing.\\n* **DALL-E 2:** An image-generating model that can create images from textual descriptions.\\n* **Jukebox:** An audio-generating model that can synthesize music in various styles.\\n\\n**Ethical Considerations:**\\n\\nThe development and deployment of generative AI raise ethical concerns, such as:\\n\\n* **Misinformation and Deepfakes:** Potential for creating realistic fake content that can be used for malicious purposes.\\n* **Bias and Fairness:** AI models can inherit and amplify biases present in the training data.\\n* **Copyright and Intellectual Property:** Ownership and rights to AI-generated content.\\n\\n\\nIt's important to use generative AI responsibly and address these ethical challenges to ensure its beneficial impact on society.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 488, 'prompt_tokens': 15, 'total_tokens': 503, 'completion_time': 0.887272727, 'prompt_time': 0.001942857, 'queue_time': 0.24577812400000001, 'total_time': 0.889215584}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--4eeff043-a2d6-428e-8a6d-a670d8cd7ebf-0', usage_metadata={'input_tokens': 15, 'output_tokens': 488, 'total_tokens': 503})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm.invoke(\"What is Generative AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619e083",
   "metadata": {},
   "source": [
    "## Build a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bda55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the question.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d83285",
   "metadata": {},
   "source": [
    "## Create a Chain and Query the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad6621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"## Langsmith: Your Open-Source AI Development Toolkit\\n\\nLangsmith is a powerful, **open-source** platform designed to simplify the development and deployment of AI applications, particularly those leveraging large language models (LLMs). \\n\\nThink of it as a comprehensive toolkit for anyone wanting to build with LLMs, whether you're a seasoned developer or just starting your AI journey.\\n\\n**Here's a breakdown of what makes Langsmith special:**\\n\\n**1. Streamlined Development:**\\n\\n* **Code Generation:** Langsmith helps you write code for interacting with LLMs in various programming languages.\\n* **Prompt Engineering:** It provides tools and resources to craft effective prompts that elicit desired responses from LLMs.\\n* **Experimentation:**  You can easily test and compare different LLM configurations and prompt variations.\\n\\n**2. Diverse Integrations:**\\n\\n* **Multiple LLMs:** Langsmith supports a wide range of LLMs, including popular models like GPT-3, Jurassic-1 Jumbo, and even custom models.\\n* **Data Pipelines:** It integrates with various data sources and formats, making it easy to feed your AI applications with the right information.\\n* **Cloud Platforms:** You can deploy Langsmith applications on popular cloud platforms like AWS, GCP, and Azure.\\n\\n**3. Open and Collaborative:**\\n\\n* **Open-Source:** The entire platform is open-source, meaning you can access, modify, and contribute to its development.\\n* **Community Support:** Langsmith boasts a vibrant community of developers and researchers who share knowledge, best practices, and solutions.\\n\\n**4. Focus on Transparency and Control:**\\n\\n* **Explainability:** Langsmith aims to provide insights into how LLMs arrive at their outputs, promoting transparency and understanding.\\n* **Fine-Tuning:** It offers tools for fine-tuning LLMs on specific tasks or domains, allowing you to customize their behavior.\\n\\n**Overall, Langsmith empowers developers and researchers to:**\\n\\n* **Build innovative AI applications**\\n* **Experiment with cutting-edge LLM technologies**\\n* **Contribute to the open-source AI ecosystem**\\n\\n\\n\\nLangsmith is constantly evolving and expanding its capabilities. Keep an eye on its official website and community forums for the latest updates and developments.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 462, 'prompt_tokens': 32, 'total_tokens': 494, 'completion_time': 0.84, 'prompt_time': 0.002317446, 'queue_time': 0.242133147, 'total_time': 0.842317446}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--2add4421-edc7-4820-b65a-efe7699e50ec-0' usage_metadata={'input_tokens': 32, 'output_tokens': 462, 'total_tokens': 494}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fef333",
   "metadata": {},
   "source": [
    "## Use an Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e27462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolbox specifically built for interacting with and leveraging the capabilities of LLMs like GPT-3, LaMDA, or Jurassic-1 Jumbo. \n",
      "\n",
      "Here's a breakdown of what makes LangChain special:\n",
      "\n",
      "**1. Modular and Flexible:**\n",
      "\n",
      "LangChain breaks down the complex process of building LLM applications into smaller, reusable components called \"chains.\" These chains can be combined and customized to create sophisticated workflows.\n",
      "\n",
      "**2. Memory Management:**\n",
      "\n",
      "LLMs have a limited memory, forgetting past interactions in a conversation. LangChain addresses this with its memory management capabilities. It allows you to store and retrieve context from previous turns, enabling your applications to maintain a coherent conversation history.\n",
      "\n",
      "**3. Integration with External Data:**\n",
      "\n",
      "LangChain empowers your applications to access and process information beyond the LLM's internal knowledge. It seamlessly integrates with various data sources like APIs, databases, and files, allowing LLMs to retrieve real-time information or leverage structured data for more informed responses.\n",
      "\n",
      "**4. Agent Functionality:**\n",
      "\n",
      "LangChain introduces the concept of \"agents,\" which are LLM-powered entities capable of taking actions in the real world. Agents can be instructed to perform tasks like searching the web, sending emails, or controlling smart devices.\n",
      "\n",
      "**5. Streamlining Development:**\n",
      "\n",
      "LangChain provides a set of pre-built tools and utilities that accelerate the development process. It offers abstractions for common LLM interactions, simplifying tasks like prompting, tokenization, and response handling.\n",
      "\n",
      "**In essence, LangChain empowers developers to:**\n",
      "\n",
      "* Build more intelligent and context-aware LLM applications.\n",
      "* Extend the capabilities of LLMs by connecting them to external data and tools.\n",
      "* Create autonomous agents that can interact with the world.\n",
      "* Develop LLM applications more efficiently and effectively.\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about LangChain or LLMs in general. I'm happy to provide more details or examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# string output parser, gets an AI message and we can choose how we wish to display it \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "chain = prompt|llm|parser\n",
    "\n",
    "response2 = chain.invoke({\"input\":\"Tell em something about Langchain.\"})\n",
    "print(response2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
