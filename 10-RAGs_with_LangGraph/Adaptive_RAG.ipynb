{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8664b1ce",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "Framework that dynamically adjusts its stratergy to handling queries based on their complexity.<br>\n",
    "It is like having a smart assistant that knows when to dig deep for information and when to provide a simple answer.<br>\n",
    "Instead of single and rigid approach, it chooses the most appropriate retrieval method for each query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25616a0a",
   "metadata": {},
   "source": [
    "### Major Components:\n",
    "1. **Query Analysis**: Take a question and based on the question, try to route it to a specific router (web search, retriever, etc.)\n",
    "\n",
    "2. **Self-corrective RAG**: Advanced RAG that has improved accuracy and relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8d8defc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"MISTRAL_API_KEY\"]=os.getenv(\"MISTRAL_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "882615c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:181: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Retriever\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Set embeddings\n",
    "embd = MistralAIEmbeddings()\n",
    "\n",
    "# Docs to index\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorstore\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=MistralAIEmbeddings()\n",
    ")\n",
    "\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d8791932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router\n",
    "from typing_extensions import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class route_query(BaseModel):\n",
    "    \"\"\"Route user query to most suitable data source.\"\"\"\n",
    "    data_source: Literal[\"vector_store\", \"web_search\",] = Field(description=\"Given a user question, choose to route it to either 'vector_store' or 'web_search'\")\n",
    "\n",
    "llm = ChatGroq(model = \"gemma2-9b-it\")\n",
    "router_llm = llm.with_structured_output(route_query)\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    ( \"system\",\"\"\"\n",
    "                You are an expert at routing a user question to a vector_store or web_search.              \n",
    "                The vector_store contains documents related to agents, prompt engineering and adversarial attacks.\n",
    "                Use the vector_store for questions on these topics. Otherwise, use web_search.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"Question: {question}\",)\n",
    "])\n",
    "question_router = router_prompt | router_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "933b4a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web_search'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = question_router.invoke({\"question\":\"What is average height of a human.\"})\n",
    "temp.data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fe07f995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_store'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_router.invoke({\"question\":\"What is Agentic AI.\"}).data_source\n",
    "# the router is working perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "334572f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Grader\n",
    "\n",
    "class gradescore(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents\"\"\"\n",
    "    score: Literal[\"relevant\", \"irrelevant\"] = Field(description=\"Whether the documents are 'relevant' to the query or 'irrelevant'\")\n",
    "\n",
    "llm = ChatGroq(model= \"gemma2-9b-it\")\n",
    "grader_llm = llm.with_structured_output(gradescore)\n",
    "\n",
    "grader_prompt = ChatPromptTemplate.from_messages([\n",
    "    ( \"system\",\"\"\"\n",
    "     You are a grader assessing relevance of a retrieved document to a user question. \n",
    "     If the document contains keyword(s) or semantic meaning related to the question, score it as relevant. \n",
    "     Give a binary score 'relevant' or 'irrelevant' score to indicate whether the document is relevant to the question or not.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"Retrieved Document:\\n\\n{documents} \\n\\nQuestion: {question}\",)\n",
    "])\n",
    "\n",
    "document_grader = grader_prompt | grader_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34bcced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradescore(score='relevant')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"prompt engineering\"\n",
    "temp_docs = retriever.invoke(question)\n",
    "document_grader.invoke({\"documents\":temp_docs, \"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b298a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradescore(score='irrelevant')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Guard Dogs\"\n",
    "temp_docs = retriever.invoke(question)\n",
    "document_grader.invoke({\"documents\":temp_docs, \"question\":question})\n",
    "# the grader is working perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "13c92180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question that user asks based on the context provided.\"),\n",
    "    (\"human\", \"Context: \\n{documents}\\n\\n Question: \\n{question}\")\n",
    "])\n",
    "\n",
    "generator = generator_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "766dd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While the provided text focuses on adversarial attacks against LLMs, it does touch upon prompt engineering in passing. \n",
      "\n",
      "Here's what we can infer about prompt engineering from the context:\n",
      "\n",
      "* **It's related to how LLMs understand and respond to input:** The text mentions \"in-context learning\" as an example of short-term memory used by LLMs. Prompt engineering likely involves carefully crafting these input \"prompts\" to guide the LLM's response in a desired direction.\n",
      "* **It's crucial for controlling LLM output:** The text states that \"attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.\" This implies that  prompt engineering can be used not only for beneficial purposes but also for malicious ones.\n",
      "\n",
      "\n",
      "Essentially, **prompt engineering is the art and science of designing effective inputs (prompts) for LLMs to elicit the desired output.** It involves understanding how LLMs process language and using that knowledge to craft prompts that are clear, concise, and steer the model towards the intended response. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = generator.invoke({\"documents\":temp_docs, \"question\":\"what is prompt engineering?\"})\n",
    "print(temp)\n",
    "# generator works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d762d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hallucination Checker\n",
    "\n",
    "class grounded(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation\"\"\"\n",
    "    score: Literal[\"not_hallucinating\", \"hallucinating\"] = Field(description=\"Whether the generation is grounded in the facts ,i.e. not_hallucinating,  or it is not grounded in the facts, i.e. hallucinating.\")\n",
    "\n",
    "llm = ChatGroq(model= \"gemma2-9b-it\")\n",
    "hallucination_checker_llm = llm.with_structured_output(grounded)\n",
    "\n",
    "hallucination_checker_prompt = ChatPromptTemplate.from_messages([\n",
    "    ( \"system\",\"\"\"\n",
    "     You are a grader assessing whether an LLM generation is grounded in/ supported by a set of retrieved facts. \n",
    "     Give a binary score 'hallucinating' or 'not_hallucinating' to indicate whether the generation is grounded in/ supported by the facts.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"Set of facts:\\n\\n{documents} \\n\\n LLM Generation: {generation}\",)\n",
    "])\n",
    "\n",
    "hallucination_checker = hallucination_checker_prompt | hallucination_checker_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0b3d0260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grounded(score='not_hallucinating')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_checker.invoke({\"documents\":temp_docs, \"generation\":temp})\n",
    "# hallucination checker works good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bfd8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Grader\n",
    "\n",
    "class answerscore(BaseModel):\n",
    "    \"\"\"Binary score to check if answer addresses question\"\"\"\n",
    "    score: Literal[\"addresses\", \"ignores\"] = Field(description=\"Whether the answer 'addresses' the question or 'ignores' it\")\n",
    "\n",
    "llm = ChatGroq(model= \"gemma2-9b-it\")\n",
    "answer_grader_llm = llm.with_structured_output(answerscore)\n",
    "\n",
    "answer_grader_prompt = ChatPromptTemplate.from_messages([\n",
    "    ( \"system\",\"\"\"\n",
    "     You are a grader assessing whether an answer addresses/resolves a question or not. \n",
    "     Give a binary score 'addresses' or 'ingores'. 'addresses' means the answer resolves the question, 'ignores' if otherwise.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"Question:\\n\\n{question} \\n\\n Answer: {generation}\",)\n",
    "])\n",
    "\n",
    "answer_grader = answer_grader_prompt | answer_grader_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "228d2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question Rewriter\n",
    "\n",
    "question_rewriter_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "         You are a rephrasing assistant. Your only job is to rephrase the following question without changing its original meaning. \n",
    "         Do not add any explanation, preface, or extra text. Only output the rephrased question.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = question_rewriter_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7d88887e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do you effectively design input prompts for AI models? \\n'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\":\"What is prompt engineering?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "838b2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Search \n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb3e5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize graph state\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents state of the graph\n",
    "\n",
    "    attributes:\n",
    "    question: The user query\n",
    "    documents: Documents retrieved wrt user query\n",
    "    answer: Output generated by llm wrt to retrieved documents and user qeury\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    documents: list[str]\n",
    "    generation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6eb9ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the nodes\n",
    "from langchain.schema import Document\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve Documents\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    state(dict) : New key added to state, documents, that contain retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\":documents, \"question\":question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate Answer\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    state(dict) : New key added to state, generation, that contain answer to the question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = generator.invoke({\"documents\":documents, \"question\":question})\n",
    "    return {\"documents\":documents, \"question\":question, \"generation\":generation}\n",
    "\n",
    "def document_grade(state):\n",
    "    \"\"\"\n",
    "    Grade relevance of retrieved documents\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    state(dict) : Updated documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "\n",
    "    # filter each doc\n",
    "    for d in documents:\n",
    "        gradescore = document_grader.invoke({\"question\":question, \"documents\":d.page_content})\n",
    "        grade = gradescore.score\n",
    "        if grade == \"relevant\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT IRRELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\":filtered_docs, \"question\":question}\n",
    "\n",
    "def question_rewrite(state):\n",
    "    \"\"\"\n",
    "    Rewrites the question\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    state(dict) : Updated question key with an optimized question\n",
    "    \"\"\"\n",
    "    print(\"---REWRITE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    new_question = question_rewriter.invoke({\"question\":question})\n",
    "    return {\"question\":new_question}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web Based search on user query\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    state(dict) : Updated document key with appended web results\n",
    "    \"\"\"\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    docs = tavily.invoke({\"query\": question})\n",
    "    web_result = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_result = Document(page_content = web_result)\n",
    "\n",
    "    return {\"documents\": web_result, \"question\": question}\n",
    "\n",
    "def question_route(state):\n",
    "    \"\"\"\n",
    "    Route query to web search or CRAG\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    str: Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ROUTE QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    datasource = question_router.invoke({\"question\":question})\n",
    "    source = datasource.data_source\n",
    "    if source == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        print(\"---ROUTE QUESTION TO VECTORSTORE---\")\n",
    "        return \"vector_store\"\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Decide to generate output or rewrite query\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    str: Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    filtered_documents = state[\"documents\"]\n",
    "    if not filtered_documents:\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUERY, REWRITE QUESTION---\")\n",
    "        return \"question_rewriter\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generator\"\n",
    "\n",
    "def hallucination_address_checker(state):\n",
    "    \"\"\"\n",
    "    Determines whether generation is grounded in document and answers\n",
    "\n",
    "    Args:\n",
    "    state(dict) : The current graph state\n",
    "\n",
    "    Returns:\n",
    "    str: Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    documents = state[\"documents\"]\n",
    "    question = state[\"question\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_checker.invoke({\"documents\":documents, \"generation\":generation})\n",
    "    score = score.score\n",
    "    if score == \"not_hallucinating\":\n",
    "        print(\"---NO HALLUCINATIONS DETECTED---\")\n",
    "\n",
    "        print(\"---CHECK ACCURACY---\")\n",
    "        address = answer_grader.invoke({\"generation\":generation, \"question\":question})\n",
    "        address = address.score\n",
    "        if address == \"addresses\":\n",
    "            print(\"---DECISION: GENERARION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not_useful\"\n",
    "    else:\n",
    "        print(\"---HALLUCINATIONS DETECTED, RETRY---\")\n",
    "        return \"not_supported\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "311fced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"document_grader\", document_grade)  # grade documents\n",
    "workflow.add_node(\"generator\", generate)  # generate\n",
    "workflow.add_node(\"question_rewriter\", question_rewrite)  # transform_query\n",
    "workflow.add_node(\"web_search\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_conditional_edges(START, question_route, {\"web_search\":\"web_search\", \"vector_store\":\"retrieve\"},)\n",
    "workflow.add_edge(\"web_search\", \"generator\")\n",
    "workflow.add_edge(\"retrieve\", \"document_grader\")\n",
    "workflow.add_conditional_edges(\"document_grader\", decide_to_generate, {\"question_rewriter\": \"question_rewriter\",\"generator\": \"generator\"},)\n",
    "workflow.add_edge(\"question_rewriter\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\"generator\", hallucination_address_checker, {\"not_supported\": \"generator\",\"useful\": END, \"not_useful\": \"question_rewriter\"},)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0630b485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3d300a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUERY---\n",
      "---ROUTE QUESTION TO VECTORSTORE---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUERY, REWRITE QUESTION---\n",
      "---REWRITE QUESTION---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUERY, REWRITE QUESTION---\n",
      "---REWRITE QUESTION---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUERY, REWRITE QUESTION---\n",
      "---REWRITE QUESTION---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE---\n",
      "---GRADE: DOCUMENT IRRELEVANT---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1014\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[179]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is machine learning?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mdocument_grade\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# filter each doc\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     gradescore = \u001b[43mdocument_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43md\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     grade = gradescore.score\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grade == \u001b[33m\"\u001b[39m\u001b[33mrelevant\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:536\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    531\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    532\u001b[39m params = {\n\u001b[32m    533\u001b[39m     **params,\n\u001b[32m    534\u001b[39m     **kwargs,\n\u001b[32m    535\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1020\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1019\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HCL Tech\\Udemy\\Gen AI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1060\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1057\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1058\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "app.invoke({\"question\":\"what is machine learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bb292019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUERY---\n",
      "---ROUTE QUESTION TO VECTORSTORE---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE---\n",
      "---ENTERING LOOP---\n",
      "---GRADING---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADING---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADING---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADING---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "DECISION: GENERATE\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---NO HALLUCINATIONS DETECTED---\n",
      "---CHECK ACCURACY---\n",
      "---DECISION: GENERARION ADDRESSES QUESTION---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is Prompt engineering?',\n",
       " 'documents': [Document(id='db936a15-44a2-422a-ab45-cd6518b70c12', metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content=\"Automatic Prompt Design\\n\\nAugmented Language Models\\n\\nRetrieval\\n\\nProgramming Language\\n\\nExternal APIs\\n\\n\\nCitation\\n\\nUseful Resources\\n\\nReferences\\n\\n\\n\\n\\n\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\"),\n",
       "  Document(id='a793b8dc-a929-46a1-b190-c66340030af6', metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content='Weng, Lilian. (Mar 2023). Prompt Engineering. LilLog. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.\\n\\nOr\\n@article{weng2023prompt,\\n  title   = \"Prompt Engineering\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Mar\",\\n  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\\n}\\nUseful Resources#\\n\\nOpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\\nLangChain, a library for combining language models with other components to build applications.\\nPrompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\\nlearnprompting.org\\nPromptPerfect\\nSemantic Kernel'),\n",
       "  Document(id='82d439de-a13a-407c-a418-167b95234322', metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content=\"Prompt Engineering | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Prompt Engineering\\n    \\nDate: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nBasic Prompting\\n\\nZero-Shot\\n\\nFew-shot\\n\\nTips for Example Selection\\n\\nTips for Example Ordering\\n\\n\\n\\nInstruction Prompting\\n\\nSelf-Consistency Sampling\\n\\nChain-of-Thought (CoT)\\n\\nTypes of CoT prompts\\n\\nTips and Extensions\\n\\n\\nAutomatic Prompt Design\\n\\nAugmented Language Models\\n\\nRetrieval\\n\\nProgramming Language\\n\\nExternal APIs\\n\\n\\nCitation\\n\\nUseful Resources\\n\\nReferences\"),\n",
       "  Document(id='11ca2a51-2b78-407a-9841-60620d5ecaf8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agents brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n \\n\\nAdversarial Attacks on LLMs\\n\\n\\n \\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\")],\n",
       " 'generation': \"Prompt engineering, also known as In-Context Prompting, is a method for communicating with Large Language Models (LLMs) to guide their behavior and achieve desired outcomes. \\n\\nIt involves carefully crafting input prompts to steer the LLM's responses without altering the model's underlying weights.  Think of it like giving clear and specific instructions to the LLM to get the results you want. \\n\\nIt's an empirical science, meaning the effectiveness of different prompting techniques can vary depending on the specific LLM and task. \\n\"}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\":\"what is Prompt engineering?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acc0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
