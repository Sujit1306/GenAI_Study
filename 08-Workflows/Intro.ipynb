{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4354c64",
   "metadata": {},
   "source": [
    "# Workflows\n",
    "Workflows are super important to implement some of the use cases.<br>\n",
    "When you're designing a workflow, you can follow some specific patterns in order to solve that complex problem.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e82a0",
   "metadata": {},
   "source": [
    "## 1. Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288bef1",
   "metadata": {},
   "source": [
    "* Prompt chaining is a technique in NLP where `multiple prompts are sequenced together` to guide a model through a `complex task`.\n",
    "\n",
    "* It breaks down the task into smaller, manageable steps, with each step building on previous one.\n",
    "\n",
    "* Improves `accuracy`, `coherence` and `control`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d76ca",
   "metadata": {},
   "source": [
    "### Usecase: Generate a Story\n",
    "* `Start`\n",
    "* `Node 1` will generate a story \n",
    "* Then we will apply a condition \n",
    "* If the story fails, `Node 1` will generate another story and try the condition\n",
    "* If the story passes, it proceeds to further nodes\n",
    "* `Node 2` will improve the story \n",
    "* `Node 3` will polish the story\n",
    "* `End`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f69b1",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "1. **Improved Context Management**: By breaking the task into smaller prompts, the model can focus on one aspect at a time. Reducing the risk of loosing context in long inputs.\n",
    "\n",
    "2. **Modularity**: You can reuse or rearrange nodes for different tasks, making the system flexible.\n",
    "\n",
    "3. **Debugging**: If something goes wrong, it is easier to pinpoint which step failed and adjust the prompt or logic accordingly.\n",
    "\n",
    "4. **Complex Reasoning**: Chaining prompts allows the model to \"think\" step-by-step, mimicking human problem-solving more effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9d655",
   "metadata": {},
   "source": [
    "## 2. Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c8030",
   "metadata": {},
   "source": [
    "* When tasks dont depend on each other's outputs, you can run them in `parallel`.\n",
    "\n",
    "* Defining `multiple nodes` that can operate independantly.\n",
    "\n",
    "* Connecting them to a `common starting point`.\n",
    "\n",
    "* `Merging their outputs` into a downstream node if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8f081",
   "metadata": {},
   "source": [
    "### Usecase: Generate a Story\n",
    "* `Start`\n",
    "* `Node 1` will generate different Characters \n",
    "* `Node 2` will generate a story premise\n",
    "* `Node 3` will generate the setting of the story\n",
    "* `Node 4` will then all these components and generate a story\n",
    "* `End`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c233b",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "1. **Speed**: Reduces total execution time by running tasks concurrently.\n",
    "\n",
    "2. **Scalability**: Handles larger workflows efficiently.\n",
    "\n",
    "3. **Modularity**: Keeps the graph structure clean and reusable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106ecf0",
   "metadata": {},
   "source": [
    "## 3. Routing (incorporating Pydantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710757ae",
   "metadata": {},
   "source": [
    "* Routing refers to the ability to `conditionally determine` which node to execute based on current state or output of the node.\n",
    "\n",
    "* This is implemented using:\n",
    "  * `add_conditional_edges`: maps node's output to various possible next nodes\n",
    "\n",
    "  * `State`: stores variables that influence routing decisions\n",
    "\n",
    "  * `Condition Functions`: evaluate state or node output to determine next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1cfdb6",
   "metadata": {},
   "source": [
    "### Usecase: LLM Call Router\n",
    "* `START` gets a user input and passes it to `Router`\n",
    "* `Router` then decides whether request is that for a poem, story or joke\n",
    "* Then the `Router` will pass that input to respective node\n",
    "* The `poem/ story/ joke node` generates requested content\n",
    "* `END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca15a72",
   "metadata": {},
   "source": [
    "## 4. Orchestrator - Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58c1ad",
   "metadata": {},
   "source": [
    "* A Central LLM dynamically breaks down tasks, delegates them to workers LLMs that work parallely and synthesizes their results.\n",
    "\n",
    "* Well suited for complex tasks where you can't predict the subtasks needed.\n",
    "\n",
    "* Key difference from parallelization is flexibility - subtasks aren't predefined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c11836",
   "metadata": {},
   "source": [
    "### Usecase: Generate a detailed & multi-section Report\n",
    "* `START`\n",
    "* `Orchestrator` will design entire Report with sections\n",
    "* For every section, it will asign a worker\n",
    "* Dynamically: section 1 to `worker 1`, section 2 to `worker 2` etc.\n",
    "* When all work is done, `Synthesizer` will combine all results\n",
    "* `END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28045fa3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
